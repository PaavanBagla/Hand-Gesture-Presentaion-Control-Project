# Hand Gesture Controller for Presentations
Control the Google Presentation slides with Hand Gesture

# Installation
**Step 1: Create and activate the conda environment**
```bash
conda create -n hand_gesture_env python=3.9 -y
conda activate hand_gesture_env
```
**Step 2: Clone GithubRepo**
```bash
git clone https://github.com/PaavanBagla/Hand-Gesture-Presentaion-Control-Project.git
```
**Step 3: Install Dependencies**
```bash
pip3 install mediapipe opencv-python pyautogui tensorflow
```
OR
```bash
pip install mediapipe opencv-python pyautogui tensorflow
```
Total Space needed for conda environment: 3.2Â GB

# Usage
Run the app with:
```bash
python3 app.py
```

# Goal
Control Google Slides via:

ğŸ‘‰ 3-fingers swipe left â†’ Next Slide

ğŸ‘ˆ 3-fingers swipe right â†’ Previous Slide

ğŸ«µ Index finger Point â†’ Spotlight pointer

ğŸ¤ Pinch Out (Index+Middle+Thumb) â†’ Zoom in 

ğŸ¤ Pinch In (Index+Middle+Thumb) â†’ Zoom out

âœŒï¸ Two-finger drag â†’ Pan Screen

# Swipe + Spotlight Control Feature
https://github.com/user-attachments/assets/248864cf-e204-47c5-91fc-a92e8f07b8e3
# Acknowledgements
This project is based on [kinivi/hand-gesture-recognition-mediapipe](https://github.com/kinivi/hand-gesture-recognition-mediapipe), which provides the core hand tracking and gesture classification logic using MediaPipe.

I have customized and extended this project for real-time presentation control with additional gesture features.
